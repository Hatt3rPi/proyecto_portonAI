{
    "NVR_ch1_main_20250414074620_20250414074630.dav": {
        "expected": [
            "FDPG32"
        ],
        "direccion": "desconocida",
        "marcha": "desconocida",
        "detected": [
            "[04/28/2025-08:49:45] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:49:45] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +9, now: CPU 0, GPU 14 (MiB)",
            "[04/28/2025-08:49:45] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.",
            "[04/28/2025-08:49:45] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:49:45] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +9, now: CPU 1, GPU 29 (MiB)"
        ],
        "success": [],
        "failed": [
            "FDPG32"
        ],
        "success_rate": 0.0
    },
    "NVR_ch1_main_20250414133110_20250414133120.dav": {
        "expected": [
            "TFWF62"
        ],
        "direccion": "desconocida",
        "marcha": "desconocida",
        "detected": [
            "[04/28/2025-08:49:56] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:49:56] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +9, now: CPU 0, GPU 14 (MiB)",
            "[04/28/2025-08:49:56] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.",
            "[04/28/2025-08:49:57] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:49:57] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +9, now: CPU 1, GPU 29 (MiB)",
            "Error al procesar respuesta de OpenAI: 'choices'"
        ],
        "success": [],
        "failed": [
            "TFWF62"
        ],
        "success_rate": 0.0
    },
    "NVR_ch1_main_20250415144940_20250415144950.dav": {
        "expected": [
            "LVKR93"
        ],
        "direccion": "desconocida",
        "marcha": "desconocida",
        "detected": [
            "[04/28/2025-08:50:08] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:50:08] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +9, now: CPU 0, GPU 14 (MiB)",
            "[04/28/2025-08:50:08] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.",
            "[04/28/2025-08:50:08] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:50:08] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +9, now: CPU 1, GPU 29 (MiB)",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "LVKR93"
        ],
        "success": [
            "LVKR93"
        ],
        "failed": [],
        "success_rate": 100.0
    },
    "NVR_ch1_main_20250415165024_20250415165034.dav": {
        "expected": [
            "FDPG32"
        ],
        "direccion": "desconocida",
        "marcha": "desconocida",
        "detected": [
            "[04/28/2025-08:50:23] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:50:23] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +9, now: CPU 0, GPU 14 (MiB)",
            "[04/28/2025-08:50:24] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.",
            "[04/28/2025-08:50:24] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:50:24] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +9, now: CPU 1, GPU 29 (MiB)"
        ],
        "success": [],
        "failed": [
            "FDPG32"
        ],
        "success_rate": 0.0
    },
    "NVR_ch1_main_20250416232152_20250416232159.dav": {
        "expected": [
            "JTJR87"
        ],
        "direccion": "desconocida",
        "marcha": "desconocida",
        "detected": [
            "[04/28/2025-08:50:37] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:50:37] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +9, now: CPU 0, GPU 14 (MiB)",
            "[04/28/2025-08:50:37] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.",
            "[04/28/2025-08:50:37] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:50:37] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +9, now: CPU 1, GPU 29 (MiB)",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "TJCR87"
        ],
        "success": [],
        "failed": [
            "JTJR87"
        ],
        "success_rate": 0.0
    },
    "NVR_ch1_main_20250417065202_20250417065214.dav": {
        "expected": [
            "LJLJ27"
        ],
        "direccion": "desconocida",
        "marcha": "desconocida",
        "detected": [
            "[04/28/2025-08:50:46] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:50:46] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +9, now: CPU 0, GPU 14 (MiB)",
            "[04/28/2025-08:50:47] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.",
            "[04/28/2025-08:50:47] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:50:47] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +9, now: CPU 1, GPU 29 (MiB)",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "CLCJ27"
        ],
        "success": [],
        "failed": [
            "LJLJ27"
        ],
        "success_rate": 0.0
    },
    "NVR_ch1_main_20250417155614_20250417155624.dav": {
        "expected": [
            "SWVT25"
        ],
        "direccion": "desconocida",
        "marcha": "desconocida",
        "detected": [
            "[04/28/2025-08:51:04] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:51:04] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +9, now: CPU 0, GPU 14 (MiB)",
            "[04/28/2025-08:51:05] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.",
            "[04/28/2025-08:51:05] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:51:05] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +9, now: CPU 1, GPU 29 (MiB)",
            "SWVV25"
        ],
        "success": [],
        "failed": [
            "SWVT25"
        ],
        "success_rate": 0.0
    },
    "NVR_ch1_main_20250422191535_20250422191540.dav": {
        "expected": [
            "JGXK82"
        ],
        "direccion": "desconocida",
        "marcha": "desconocida",
        "detected": [
            "[04/28/2025-08:51:16] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:51:16] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +9, now: CPU 0, GPU 14 (MiB)",
            "[04/28/2025-08:51:16] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.",
            "[04/28/2025-08:51:16] [TRT] [I] Loaded engine size: 9 MiB",
            "[04/28/2025-08:51:16] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +9, now: CPU 1, GPU 29 (MiB)",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'",
            "Error al procesar respuesta de OpenAI: 'choices'"
        ],
        "success": [],
        "failed": [
            "JGXK82"
        ],
        "success_rate": 0.0
    }
}